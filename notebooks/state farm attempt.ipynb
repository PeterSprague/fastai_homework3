{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Statefarm-Kaggle-submission-(fast.ai-homework3)\" data-toc-modified-id=\"Statefarm-Kaggle-submission-(fast.ai-homework3)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Statefarm Kaggle submission (fast.ai homework3)</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-structure\" data-toc-modified-id=\"Data-structure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data structure</a></div><div class=\"lev1 toc-item\"><a href=\"#VGG16()-setup-boilerplate\" data-toc-modified-id=\"VGG16()-setup-boilerplate-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>VGG16() setup boilerplate</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-in-data-with-generators\" data-toc-modified-id=\"Load-in-data-with-generators-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load in data with generators</a></div><div class=\"lev1 toc-item\"><a href=\"#Finetuning-the-model\" data-toc-modified-id=\"Finetuning-the-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Finetuning the model</a></div><div class=\"lev1 toc-item\"><a href=\"#New-model-architecture\" data-toc-modified-id=\"New-model-architecture-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>New model architecture</a></div><div class=\"lev2 toc-item\"><a href=\"#Batch-normalisation\" data-toc-modified-id=\"Batch-normalisation-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Batch normalisation</a></div><div class=\"lev2 toc-item\"><a href=\"#Data-augmentation\" data-toc-modified-id=\"Data-augmentation-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Data augmentation</a></div><div class=\"lev3 toc-item\"><a href=\"#Some-minor-debug-settings\" data-toc-modified-id=\"Some-minor-debug-settings-621\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Some minor debug settings</a></div><div class=\"lev3 toc-item\"><a href=\"#Conv-stack-output\" data-toc-modified-id=\"Conv-stack-output-622\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Conv stack output</a></div><div class=\"lev3 toc-item\"><a href=\"#Save-everything-to-disk\" data-toc-modified-id=\"Save-everything-to-disk-623\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Save everything to disk</a></div><div class=\"lev2 toc-item\"><a href=\"#Train-fully-connected-layers-only\" data-toc-modified-id=\"Train-fully-connected-layers-only-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Train fully connected layers only</a></div><div class=\"lev3 toc-item\"><a href=\"#Import-data-from-disk\" data-toc-modified-id=\"Import-data-from-disk-631\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Import data from disk</a></div><div class=\"lev3 toc-item\"><a href=\"#Use-data-to-train-model\" data-toc-modified-id=\"Use-data-to-train-model-632\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Use data to train model</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statefarm Kaggle submission (fast.ai homework3)\n",
    "What I'll need to do:\n",
    "* set up data structure into sample, train, valid, test\n",
    "* Import VGG16\n",
    "* pop the top layer, train it\n",
    "* set all fully connected layers to trainable\n",
    "* Improvements:\n",
    "    * play with dropout parameter\n",
    "    * add data augmentation\n",
    "    * stack multiple versions of the classifier\n",
    "    * apply batch norm\n",
    "    * have a setup that adjusts learning rate\n",
    "    \n",
    "These are general imports, always make sure to run these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import csv\n",
    "import bcolz\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "model_url = \"http://files.fast.ai/models/\"\n",
    "model_name = \"vgg16.h5\"\n",
    "cache_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data structure\n",
    "First we set up the data structure, with proper:\n",
    "* sample (about 10% of the data) \n",
    "* train\n",
    "* validation (about 15% of the data)\n",
    "* test \n",
    "directories in the `processed` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_path = os.path.join(os.getcwd(), os.pardir, 'data', 'raw')\n",
    "processed_path = os.path.join(os.getcwd(), os.pardir, 'data', 'processed')\n",
    "\n",
    "# Make directories sample, valid, train, test, first check if this whole step is necessary\n",
    "if os.path.exists(os.path.join(processed_path, 'sample')):\n",
    "    print 'Sample directory already exists, no need to do data structuring!'\n",
    "else:\n",
    "    os.mkdir(os.path.join(processed_path, 'sample'))\n",
    "    os.mkdir(os.path.join(processed_path, 'sample', 'train'))\n",
    "    os.mkdir(os.path.join(processed_path, 'sample', 'valid'))\n",
    "    os.mkdir(os.path.join(processed_path, 'valid'))\n",
    "    \n",
    "    # Extract Kaggle zipfiles to correct path\n",
    "    print 'Extracting zips, this may take a while...'\n",
    "    img_zip_handle = zipfile.ZipFile(os.path.join(raw_path, 'imgs.zip'), 'r')\n",
    "    img_zip_handle.extractall(processed_path)\n",
    "    img_zip_handle.close()\n",
    "    \n",
    "    csv_zip_handle = zipfile.ZipFile(os.path.join(raw_path, 'driver_imgs_list.csv.zip'), 'r')\n",
    "    csv_zip_handle.extractall(processed_path)\n",
    "    csv_zip_handle.close()\n",
    "    print 'Done extracting zips!'\n",
    "    \n",
    "    # Set up sample directory structure\n",
    "    for i in range(10):\n",
    "        dirname = 'c' + str(i)\n",
    "        os.mkdir(os.path.join(processed_path, 'sample', 'train', dirname))\n",
    "        os.mkdir(os.path.join(processed_path, 'sample', 'valid', dirname))\n",
    "        os.mkdir(os.path.join(processed_path, 'valid', dirname))\n",
    "        \n",
    "    os.mkdir(os.path.join(processed_path, 'test', 'unknown'))\n",
    "    for filename in os.listdir(os.path.join(processed_path, 'test')):\n",
    "        if filename.endswith('.jpg'):\n",
    "            src = os.path.join(processed_path, 'test', filename)\n",
    "            dest = os.path.join(processed_path, 'test', 'unknown', filename)\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "    data = np.genfromtxt(os.path.join(processed_path, 'driver_imgs_list.csv'), delimiter=',', dtype=None)\n",
    "    data = data[1:,:]\n",
    "    drivers = np.unique(data[:,0])\n",
    "    num_drivers = drivers.shape[0]\n",
    "    # Throw 15% of train data into sample folder\n",
    "    sample_drivers_amount = int(np.floor(num_drivers*0.15))\n",
    "    sample_drivers = np.random.choice(drivers, sample_drivers_amount, replace=False)\n",
    "\n",
    "    # Throw 20% of train data into valid folder\n",
    "    validation_drivers_amount = int(np.floor(num_drivers*0.2))\n",
    "    validation_drivers = np.random.choice(drivers, validation_drivers_amount, replace=False)\n",
    "\n",
    "    # Set up sample set\n",
    "    for i in range(sample_drivers_amount):\n",
    "        driver_name = sample_drivers[i]\n",
    "        driver_columns = data[data[:,0] == driver_name]\n",
    "        for j in range(10):\n",
    "            driver_class = 'c' + str(j)\n",
    "            dest = os.path.join(processed_path, 'sample', 'train', driver_class)\n",
    "            class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "            for filename in class_columns[:,2]:\n",
    "                src = os.path.join(processed_path, 'train', driver_class, filename)\n",
    "                shutil.copyfile(src, os.path.join(dest, filename))\n",
    "\n",
    "    # Now move from sample_train to sample_validation a fraction of ~40%\n",
    "    sample_drivers_validation_amount = int(np.floor(sample_drivers_amount*0.4))\n",
    "    sample_drivers_validation = np.random.choice(sample_drivers, \n",
    "                                                 sample_drivers_validation_amount, \n",
    "                                                 replace=False)\n",
    "\n",
    "    for i in range(sample_drivers_validation_amount):\n",
    "        driver_name = sample_drivers_validation[i]\n",
    "        driver_columns = data[data[:,0] == driver_name]\n",
    "        for j in range(10):\n",
    "            driver_class = 'c' + str(j)\n",
    "            class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "            for filename in class_columns[:,2]:\n",
    "                dest = os.path.join(processed_path, 'sample', 'valid', driver_class, filename)\n",
    "                src = os.path.join(processed_path, 'sample', 'train', driver_class, filename)\n",
    "                shutil.move(src, dest)\n",
    "\n",
    "    # Set up validation set\n",
    "    for i in range(validation_drivers_amount):\n",
    "        driver_name = validation_drivers[i]\n",
    "        driver_columns = data[data[:,0] == driver_name]\n",
    "\n",
    "        for j in range(10):\n",
    "            driver_class = 'c' + str(j)\n",
    "            class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "            for filename in class_columns[:,2]:\n",
    "                src = os.path.join(processed_path, 'train', driver_class, filename)\n",
    "                dest = os.path.join(processed_path, 'valid', driver_class, filename)\n",
    "                shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# VGG16() setup boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_conv_block(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    return model\n",
    "    \n",
    "def add_fc_block(model, dropout):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class vgg16():\n",
    "    def __init__(self, dropout=0.5):\n",
    "        self.vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([3,1,1])\n",
    "        self.create(dropout)\n",
    "        \n",
    "    def create(self, dropout):\n",
    "        def vgg_preprocess(x, mean):\n",
    "            mean = np.array(mean)\n",
    "            x = x - mean\n",
    "            return x[:,:,::-1]\n",
    "        \n",
    "        model = self.model = Sequential()\n",
    "        \n",
    "        model.add(Lambda(vgg_preprocess, \n",
    "                         input_shape=(3, 244, 244), \n",
    "                         output_shape=(3, 244, 244),\n",
    "                         arguments = {'mean': self.vgg_mean.tolist()}\n",
    "                        ))\n",
    "        \n",
    "        model = add_conv_block(model, 2, 64)\n",
    "        model = add_conv_block(model, 2, 128)\n",
    "        model = add_conv_block(model, 3, 256)\n",
    "        model = add_conv_block(model, 3, 512)\n",
    "        model = add_conv_block(model, 3, 512)\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model = add_fc_block(model, dropout)\n",
    "        model = add_fc_block(model, dropout)\n",
    "        model.add(Dense(1000, activation='softmax'))\n",
    "        \n",
    "        model = model.load_weights(get_file(model_name, model_url+model_name, cache_subdir=cache_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load in data with generators\n",
    "Here I set up the generators for the training and validation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "data_dir = os.path.join(os.getcwd(), os.pardir, 'data')\n",
    "model_dir = os.path.join(os.getcwd(), os.pardir, 'models')\n",
    "if DEBUG == True:\n",
    "    path = os.path.join(data_dir, 'processed', 'sample')\n",
    "    batch_size = 4\n",
    "    epochs = 2\n",
    "elif DEBUG == False:\n",
    "    path = os.path.join(data_dir, 'processed')\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'valid')\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, \n",
    "                                                         target_size=(244,244), \n",
    "                                                         batch_size=batch_size, \n",
    "                                                         shuffle=True)\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, \n",
    "                                                       target_size=(244,244), \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model\n",
    "* Now the top layer must be popped and replaced with a 10-output, which will correspond to our hot-encoding/softmax output\n",
    "* Then retrain model with new dense layer, which will be a good starting point for later fine tuning\n",
    "* Save the model, so that we can start toying with it in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "model = vgg16(dropout=0.5).model\n",
    "model.pop()\n",
    "for layer in model.layers: layer.trainable=False\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, \n",
    "                    samples_per_epoch=train_batches.nb_sample, \n",
    "                    nb_epoch=epochs, \n",
    "                    validation_data=val_batches, \n",
    "                    nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "model.save(os.path.join(model_dir, 'model_with_new_top.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model architecture\n",
    "Now that we have the trained model, we should probably make all the FC layers trainable. Additionally, we can start playing with:\n",
    "* learning rate schedule\n",
    "* batchnorm\n",
    "* data augmentation\n",
    "* setting different epochs\n",
    "* some other kind of regularisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the model from when we saved it. Then:\n",
    "* Separate convolutional layers from fully connected ones\n",
    "* Make a new convolutional architecture with whatever we want to implement\n",
    "* Put them together\n",
    "* Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_model = load_model(os.path.join(os.getcwd(), \n",
    "                                    os.pardir, \n",
    "                                    'models', \n",
    "                                    'model_with_new_top.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Batch normalisation\n",
    "Let's implement batch normalisation first. It'll speed up our looking for the adequate learning rate. From [this link](https://github.com/fchollet/keras/issues/1802) we know that `BatchNorm()` needs to be applied after the activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_index = [index for index,layer in enumerate(old_model.layers) if type(layer).__name__ == 'Flatten'][0]\n",
    "\n",
    "conv_model_layers = old_model.layers[1:flatten_index-1]\n",
    "conv_model = Sequential(conv_model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_model(dropout):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(MaxPooling2D(input_shape=conv_model.layers[-1].output_shape[1:]))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Let's set up new batch generators, this time making use of augmented data. Remember, we only seek to augment our **training** input, no need to augment validation input (there's no learning taking place).\n",
    "`train_batches` generator is set to `False` because we're going to be saving it, and need reproducible inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Some minor debug settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "data_dir = os.path.join(os.getcwd(), os.pardir, 'data')\n",
    "model_dir = os.path.join(os.getcwd(), os.pardir, 'models')\n",
    "if DEBUG == True:\n",
    "    path = os.path.join(data_dir, 'processed', 'sample')\n",
    "    batch_size = 4\n",
    "    epochs = 2\n",
    "elif DEBUG == False:\n",
    "    path = os.path.join(data_dir, 'processed')\n",
    "    batch_size = 64\n",
    "    epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv stack output\n",
    "Using only the convolutional part of VGG16, I generate the predictions, based on some augmented data, and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'valid')\n",
    "\n",
    "train_image_gen = ImageDataGenerator(rotation_range=15,\n",
    "                                     height_shift_range=0.05,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     shear_range = 0.1,\n",
    "                                     channel_shift_range=20,\n",
    "                                    )\n",
    "\n",
    "aug_train_batches = train_image_gen.flow_from_directory(train_path, \n",
    "                                                    target_size=(244,244), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, \n",
    "                                                    target_size=(244,244), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, \n",
    "                                                       target_size=(244,244), \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       shuffle=False)\n",
    "\n",
    "print 'Predicting, this may take a while...'\n",
    "conv_model_predictions_augmented = conv_model.predict_generator(aug_train_batches,\n",
    "                                                                aug_train_batches.nb_sample*2,\n",
    "                                                               )\n",
    "conv_model_predictions = conv_model.predict_generator(train_batches,\n",
    "                                                      train_batches.nb_sample,\n",
    "                                                     )\n",
    "val_predictions = conv_model.predict_generator(val_batches,\n",
    "                                               val_batches.nb_sample,\n",
    "                                              )\n",
    "\n",
    "print 'Done predicting!'\n",
    "# Concatenating augmented and non-augmented predictions\n",
    "conv_model_predictions = np.concatenate([conv_model_predictions_augmented, conv_model_predictions])\n",
    "\n",
    "prediction_labels = to_categorical(train_batches.classes)\n",
    "\n",
    "prediction_labels = np.concatenate([prediction_labels]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "Predicting test features, this might take a while...\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(path, 'test')\n",
    "test_generator = ImageDataGenerator().flow_from_directory(test_path, \n",
    "                                                    target_size=(244,244), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "print 'Predicting test features, this might take a while...'\n",
    "conv_model_test_inputs = conv_model.predict_generator(test_generator,\n",
    "                                                      test_generator.nb_sample,\n",
    "                                                      nb_worker=3,\n",
    "                                                      pickle_safe=True\n",
    "                                                     )\n",
    "print 'Done predicting!'\n",
    "\n",
    "save_array(os.path.join(model_dir, 'test_inputs.bc'), conv_model_test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save everything to disk\n",
    "Saving everything to disk so I don't need to generate it every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_array(location, array):\n",
    "    instance = bcolz.carray(array, rootdir=location, mode='w')\n",
    "    instance.flush()\n",
    "    \n",
    "def load_array(location):\n",
    "    return bcolz.open(location)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(os.path.join(model_dir, 'conv_predictions.bc'), conv_model_predictions)\n",
    "save_array(os.path.join(model_dir, 'conv_labels.bc'), prediction_labels)\n",
    "save_array(os.path.join(model_dir, 'val_predictions.bc'), val_predictions)\n",
    "save_array(os.path.join(model_dir, 'val_labels.bc'), to_categorical(val_batches.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fully connected layers only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_predictions = load_array(os.path.join(model_dir, 'conv_predictions.bc'))\n",
    "conv_labels = load_array(os.path.join(model_dir, 'conv_labels.bc'))\n",
    "conv_val_predictions = load_array(os.path.join(model_dir, 'val_predictions.bc'))\n",
    "conv_val_labels = load_array(os.path.join(model_dir, 'val_labels.bc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropout = 0.8\n",
    "model = fc_model(dropout)\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "model.compile(optimizer=Adam(lr), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.optimizer.lr.set_value(lr)\n",
    "model.fit(conv_predictions,\n",
    "          conv_labels,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=epochs,\n",
    "          validation_data=(conv_val_predictions, conv_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "epochs = 2\n",
    "model.optimizer.lr.set_value(lr)\n",
    "model.fit(conv_predictions,\n",
    "          conv_labels,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=epochs,\n",
    "          validation_data=(conv_val_predictions, conv_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(model_dir, 'final_predictor.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_input = load_array(os.path.join(model_dir, 'test_inputs.bc'))\n",
    "\n",
    "predictions = model.fit(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "251px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
