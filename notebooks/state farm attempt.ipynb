{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Statefarm Kaggle submission (fast.ai homework3)\n",
    "What I'll need to do:\n",
    "* set up data structure into sample, train, valid, test\n",
    "* Import VGG16\n",
    "* pop the top layer, train it\n",
    "* set all fully connected layers to trainable\n",
    "* Improvements:\n",
    "    * play with dropout parameter\n",
    "    * add data augmentation\n",
    "    * stack multiple versions of the classifier\n",
    "    * apply batch norm\n",
    "    * have a setup that adjusts learning rate\n",
    "    \n",
    "These are general imports, always make sure to run these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import csv\n",
    "import bcolz\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "model_url = \"http://files.fast.ai/models/\"\n",
    "model_name = \"vgg16.h5\"\n",
    "cache_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data structure\n",
    "First we set up the data structure, with proper:\n",
    "* sample \n",
    "* train\n",
    "* validation\n",
    "* test \n",
    "directories in the `processed` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_path = os.path.join(os.getcwd(), os.pardir, 'data', 'raw')\n",
    "processed_path = os.path.join(os.getcwd(), os.pardir, 'data', 'processed')\n",
    "\n",
    "# Make directories sample, valid, train, test, first check if this whole step is necessary\n",
    "if os.path.exists(os.path.join(processed_path, 'sample')):\n",
    "    print 'Sample directory already exists, no need to do data structuring!'\n",
    "else:\n",
    "    os.mkdir(os.path.join(processed_path, 'sample'))\n",
    "    os.mkdir(os.path.join(processed_path, 'sample', 'train'))\n",
    "    os.mkdir(os.path.join(processed_path, 'sample', 'valid'))\n",
    "    os.mkdir(os.path.join(processed_path, 'valid'))\n",
    "    \n",
    "    # Extract Kaggle zipfiles to correct path\n",
    "    print 'Extracting zips, this may take a while...'\n",
    "    img_zip_handle = zipfile.ZipFile(os.path.join(raw_path, 'imgs.zip'), 'r')\n",
    "    img_zip_handle.extractall(processed_path)\n",
    "    img_zip_handle.close()\n",
    "    \n",
    "    csv_zip_handle = zipfile.ZipFile(os.path.join(raw_path, 'driver_imgs_list.csv.zip'), 'r')\n",
    "    csv_zip_handle.extractall(processed_path)\n",
    "    csv_zip_handle.close()\n",
    "    print 'Done extracting zips!'\n",
    "    \n",
    "    # Set up sample directory structure\n",
    "    for i in range(10):\n",
    "        dirname = 'c' + str(i)\n",
    "        os.mkdir(os.path.join(processed_path, 'sample', 'train', dirname))\n",
    "        os.mkdir(os.path.join(processed_path, 'sample', 'valid', dirname))\n",
    "        os.mkdir(os.path.join(processed_path, 'valid', dirname))\n",
    "        \n",
    "    data = np.genfromtxt(os.path.join(processed_path, 'driver_imgs_list.csv'), delimiter=',', dtype=None)\n",
    "    data = data[1:,:]\n",
    "    drivers = np.unique(data[:,0])\n",
    "    sample_drivers = np.random.choice(drivers, 3, replace=False)\n",
    "    for i in range(2):\n",
    "        driver_name = sample_drivers[i]\n",
    "        driver_columns = data[data[:,0] == driver_name]\n",
    "        for j in range(10):\n",
    "            driver_class = 'c' + str(j)\n",
    "            dest = os.path.join(processed_path, 'sample', 'train', driver_class)\n",
    "\n",
    "            class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "            filenames = np.random.choice(class_columns[:,2], 3, replace=False)\n",
    "            for filename in filenames:\n",
    "                src = os.path.join(processed_path, 'train', driver_class, filename)\n",
    "                shutil.copyfile(src, os.path.join(dest, filename))\n",
    "\n",
    "    # Fill in validation driver\n",
    "    driver_name = sample_drivers[2]\n",
    "    driver_columns = data[data[:,0] == driver_name]\n",
    "    for j in range(10):\n",
    "        driver_class = 'c' + str(j)\n",
    "        dest = os.path.join(processed_path, 'sample', 'valid', driver_class)\n",
    "\n",
    "        class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "        filenames = np.random.choice(class_columns[:,2], 3, replace=False)\n",
    "        for filename in filenames:\n",
    "            src = os.path.join(processed_path, 'train', driver_class, filename)\n",
    "            shutil.copyfile(src, os.path.join(dest, filename))\n",
    "            \n",
    "    # Throw 30% of train data into valid folder\n",
    "    num_drivers = drivers.shape[0]\n",
    "    validation_drivers_amount = int(np.floor(num_drivers*0.3))\n",
    "    validation_drivers = np.random.choice(drivers, validation_drivers_amount, replace=False)\n",
    "\n",
    "    for i in range(validation_drivers_amount):\n",
    "        driver_name = validation_drivers[i]\n",
    "        driver_columns = data[data[:,0] == driver_name]\n",
    "\n",
    "        for j in range(10):\n",
    "            driver_class = 'c' + str(j)\n",
    "            class_columns = driver_columns[driver_columns[:,1] == driver_class]\n",
    "            for filename in class_columns[:,2]:\n",
    "                src = os.path.join(processed_path, 'train', driver_class, filename)\n",
    "                dest = os.path.join(processed_path, 'valid', driver_class, filename)\n",
    "                shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# VGG16() setup boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([3,1,1])\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:,:,::-1]\n",
    "\n",
    "def add_conv_block(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    return model\n",
    "    \n",
    "def add_fc_block(model, dropout):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class vgg16():\n",
    "    def __init__(self, dropout=0.5):\n",
    "        self.create(dropout)\n",
    "        \n",
    "    def create(self, dropout):\n",
    "        model = self.model = Sequential()\n",
    "        \n",
    "        model.add(Lambda(vgg_preprocess, input_shape=(3, 244, 244), output_shape=(3, 244, 244)))\n",
    "        \n",
    "        model = add_conv_block(model, 2, 64)\n",
    "        model = add_conv_block(model, 2, 128)\n",
    "        model = add_conv_block(model, 3, 256)\n",
    "        model = add_conv_block(model, 3, 512)\n",
    "        model = add_conv_block(model, 3, 512)\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model = add_fc_block(model, dropout)\n",
    "        model = add_fc_block(model, dropout)\n",
    "        model.add(Dense(1000, activation='softmax'))\n",
    "        \n",
    "        model = model.load_weights(get_file(model_name, model_url+model_name, cache_subdir=cache_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load in data with generators\n",
    "Here I set up the generators for the training and validation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "data_dir = os.path.join(os.getcwd(), os.pardir, 'data')\n",
    "model_dir = os.path.join(os.getcwd(), os.pardir, 'models')\n",
    "if DEBUG == True:\n",
    "    path = os.path.join(data_dir, 'processed', 'sample')\n",
    "    batch_size = 4\n",
    "    epochs = 2\n",
    "elif DEBUG == False:\n",
    "    path = os.path.join(data_dir, 'processed')\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'valid')\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(244,244), batch_size=batch_size, shuffle=True)\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, target_size=(244,244), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model\n",
    "* Now the top layer must be popped and replaced with a 10-output, which will correspond to our hot-encoding.\n",
    "* Then retrain model with new dense layer, which will be a good starting point for later fine tuning\n",
    "* Save the model, so that we can start toying with it in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "model = vgg16(dropout=0.5).model\n",
    "model.pop()\n",
    "for layer in model.layers: layer.trainable=False\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, \n",
    "                    samples_per_epoch=train_batches.nb_sample, \n",
    "                    nb_epoch=epochs, \n",
    "                    validation_data=val_batches, \n",
    "                    nb_val_samples=val_batches.nb_sample)\n",
    "model.model.save(os.path.join(model_dir, 'model_with_new_top.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model architecture\n",
    "Now that we have the trained model, we should probably make all the FC layers trainable. Additionally, we can start playing with:\n",
    "* learning rate schedule\n",
    "* batchnorm\n",
    "* data augmentation\n",
    "* setting different epochs\n",
    "* some other kind of regularisation?\n",
    "\n",
    "First, import the model from when we saved it. Then:\n",
    "* Separate convolutional layers from fully connected ones\n",
    "* Make a new convolutional architecture with whatever we want to implement\n",
    "* Put them together\n",
    "* Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([3,1,1])\n",
    "\n",
    "old_model = load_model(os.path.join(os.getcwd(), \n",
    "                                    os.pardir, \n",
    "                                    'models', \n",
    "                                    'model_with_new_top.h5'), \n",
    "                       custom_objects={'vgg_mean': vgg_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Batch normalisation\n",
    "Let's implement batch normalisation first. It'll speed up our looking for the adequate learning rate. From [this link](https://github.com/fchollet/keras/issues/1802) we know that `BatchNorm()` needs to be applied after the activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_index = [index for index,layer in enumerate(old_model.layers) if type(layer).__name__ == 'Flatten'][0]\n",
    "\n",
    "conv_model_layers = old_model.layers[1:flatten_index-1]\n",
    "conv_model = Sequential(conv_model_layers)\n",
    "\n",
    "def fc_model(dropout):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(MaxPooling2D(input_shape=conv_model.layers[-1].output_shape[1:]))\n",
    "#     model.layers[-1].name='maxpool_appended' # Shim because otherwise it would throw a dupe name error for no clear reason\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Let's set up new batch generators, this time making use of augmented data. Remember, we only seek to augment our **training** input, no need to augment validation input (there's no learning taking place).\n",
    "`train_batches` generator is set to `False` because we're going to be saving it, and need reproducible inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Some minor debug settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "data_dir = os.path.join(os.getcwd(), os.pardir, 'data')\n",
    "model_dir = os.path.join(os.getcwd(), os.pardir, 'models')\n",
    "if DEBUG == True:\n",
    "    path = os.path.join(data_dir, 'processed', 'sample')\n",
    "    batch_size = 4\n",
    "    epochs = 2\n",
    "elif DEBUG == False:\n",
    "    path = os.path.join(data_dir, 'processed')\n",
    "    batch_size = 64\n",
    "    epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv stack output\n",
    "Using only the convolutional part of VGG16, I generate the predictions, based on some augmented data, and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'valid')\n",
    "\n",
    "train_image_gen = ImageDataGenerator(rotation_range=15,\n",
    "                                     height_shift_range=0.05,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     shear_range = 0.1,\n",
    "                                     channel_shift_range=20,\n",
    "                                    )\n",
    "\n",
    "aug_train_batches = train_image_gen.flow_from_directory(train_path, \n",
    "                                                    target_size=(244,244), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, \n",
    "                                                    target_size=(244,244), \n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, \n",
    "                                                       target_size=(244,244), \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       shuffle=False)\n",
    "\n",
    "print 'Predicting, this may take a while...'\n",
    "conv_model_predictions_augmented = conv_model.predict_generator(aug_train_batches,\n",
    "                                                 aug_train_batches.nb_sample*5)\n",
    "conv_model_predictions = conv_model.predict_generator(train_batches,\n",
    "                                                 train_batches.nb_sample)\n",
    "val_predictions = conv_model.predict_generator(val_batches,\n",
    "                                               val_batches.nb_sample)\n",
    "\n",
    "print 'Done predicting!'\n",
    "# Concatenating augmented and non-augmented predictions\n",
    "conv_model_predictions = np.concatenate([conv_model_predictions_augmented, conv_model_predictions])\n",
    "\n",
    "prediction_labels = to_categorical(train_batches.classes)\n",
    "prediction_labels = np.concatenate([prediction_labels]*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save everything to disk\n",
    "Saving everything to disk so I don't need to generate it every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array(location, array):\n",
    "    instance = bcolz.carray(array, rootdir=location, mode='w')\n",
    "    instance.flush()\n",
    "    \n",
    "def load_array(location):\n",
    "    return bcolz.open(location)[:]\n",
    "\n",
    "save_array(os.path.join(model_dir, 'conv_predictions.bc'), conv_model_predictions)\n",
    "save_array(os.path.join(model_dir, 'conv_labels.bc'), prediction_labels)\n",
    "save_array(os.path.join(model_dir, 'val_predictions.bc'), val_predictions)\n",
    "save_array(os.path.join(model_dir, 'val_labels.bc'), to_categorical(val_batches.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fully connected layers only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_predictions = load_array(os.path.join(model_dir, 'conv_predictions.bc'))\n",
    "conv_labels = load_array(os.path.join(model_dir, 'conv_labels.bc'))\n",
    "conv_val_predictions = load_array(os.path.join(model_dir, 'val_predictions.bc'))\n",
    "conv_val_labels = load_array(os.path.join(model_dir, 'val_labels.bc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "360/360 [==============================] - 3s - loss: 2.2584 - acc: 0.2944 - val_loss: 2.5503 - val_acc: 0.1667\n",
      "Epoch 2/10\n",
      "360/360 [==============================] - 3s - loss: 1.3328 - acc: 0.5556 - val_loss: 2.4033 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "360/360 [==============================] - 3s - loss: 0.9278 - acc: 0.7028 - val_loss: 2.4364 - val_acc: 0.3000\n",
      "Epoch 4/10\n",
      "360/360 [==============================] - 3s - loss: 0.8394 - acc: 0.7167 - val_loss: 2.0213 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "360/360 [==============================] - 3s - loss: 0.6721 - acc: 0.8194 - val_loss: 2.0730 - val_acc: 0.2667\n",
      "Epoch 6/10\n",
      "360/360 [==============================] - 3s - loss: 0.6060 - acc: 0.8361 - val_loss: 2.0686 - val_acc: 0.3000\n",
      "Epoch 7/10\n",
      "360/360 [==============================] - 3s - loss: 0.4919 - acc: 0.8694 - val_loss: 2.0638 - val_acc: 0.2667\n",
      "Epoch 8/10\n",
      "360/360 [==============================] - 4s - loss: 0.4744 - acc: 0.8750 - val_loss: 2.2172 - val_acc: 0.2000\n",
      "Epoch 9/10\n",
      "360/360 [==============================] - 5s - loss: 0.3964 - acc: 0.8889 - val_loss: 2.0076 - val_acc: 0.3667\n",
      "Epoch 10/10\n",
      "360/360 [==============================] - 6s - loss: 0.3420 - acc: 0.9028 - val_loss: 1.8787 - val_acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e9f9690>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "model = fc_model(dropout)\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "model.compile(optimizer=Adam(lr), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.optimizer.lr.set_value(lr)\n",
    "model.fit(conv_predictions,\n",
    "          conv_labels,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=epochs,\n",
    "          validation_data=(conv_val_predictions, conv_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
